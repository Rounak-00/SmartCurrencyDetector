{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "PQ8V9uk6m-CE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742047751205,
     "user_tz": -330,
     "elapsed": 5845,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "import os\n",
    "import kagglehub\n",
    "from google.colab import drive\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112059,
     "status": "ok",
     "timestamp": 1742047863268,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     },
     "user_tz": -330
    },
    "id": "ph_NDvOs0pjR",
    "outputId": "da2b290b-4fc3-41e5-bfa8-0a6f8464f15f"
   },
   "source": [
    "EPOCH = 60\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "path = kagglehub.dataset_download(\"vishalmane109/indian-currency-note-images-dataset-2020\")\n",
    "drive.mount('/content/drive')\n",
    "model_save_path = '/content/drive/MyDrive/CurrencyRecognitionModels'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uDOTBrZB0pjR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742047863271,
     "user_tz": -330,
     "elapsed": 9,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.path = path\n",
    "\n",
    "    def dataset(self):\n",
    "        trainSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            os.path.join(self.path, \"Indian currency dataset v1/training\"),\n",
    "            shuffle=True,\n",
    "            image_size=(IMG_SIZE, IMG_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        valSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            os.path.join(self.path, \"Indian currency dataset v1/validation\"),\n",
    "            shuffle=True,\n",
    "            image_size=(IMG_SIZE, IMG_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        return trainSet, valSet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nd-EltnKwu-v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742047863318,
     "user_tz": -330,
     "elapsed": 52,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class Preprocessing:\n",
    "    def preprocess(self, IMG_SIZE = 224):\n",
    "        resize_and_rescale = tf.keras.Sequential([\n",
    "            layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "            layers.Rescaling(1.0 / 255),\n",
    "        ])\n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.RandomRotation(0.1),\n",
    "        ])\n",
    "        print(\"Preprocessing initialized.\")\n",
    "        return resize_and_rescale, data_augmentation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-NuYaZYjtxw1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742047863321,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class VGG16Model:\n",
    "    def __init__(self, base_models):\n",
    "        self.base_model = base_models\n",
    "        self.base_model.trainable = False\n",
    "\n",
    "    def build_model(self, IMG_SIZE = 224):\n",
    "        prep = Preprocessing()\n",
    "        resize_and_rescale, data_augmentation = prep.preprocess()\n",
    "        model = Sequential([\n",
    "            layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            resize_and_rescale,\n",
    "            data_augmentation,\n",
    "            self.base_model,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1024, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(8, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        dataset = Dataset()\n",
    "        trainSet, valSet = dataset.dataset()\n",
    "\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(f\"{model_save_path}/best_VGG16.keras\",\n",
    "                                        monitor='val_loss',\n",
    "                                        save_best_only=True,\n",
    "                                        mode='min',\n",
    "                                        verbose=1)\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        trained_model = model.fit(trainSet,\n",
    "                          validation_data=valSet,\n",
    "                          epochs=60,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          verbose=1,\n",
    "                          callbacks=[checkpoint_cb])\n",
    "        print(\"Model Trained VGG16.\")\n",
    "        model.save(f'{model_save_path}/VGG16.keras')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u1GVPFIq2u8b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742054213111,
     "user_tz": -330,
     "elapsed": 37,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class VGG19Model:\n",
    "    def __init__(self, base_model):\n",
    "        self.base_model = base_model\n",
    "        self.base_model.trainable = True\n",
    "\n",
    "    def build_model(self, IMG_SIZE=224):\n",
    "        prep = Preprocessing()\n",
    "        resize_and_rescale, data_augmentation = prep.preprocess()\n",
    "\n",
    "        model = Sequential([\n",
    "            layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            resize_and_rescale,\n",
    "            data_augmentation,\n",
    "            self.base_model,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1024, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(8, activation='softmax')  # 8 classes for classification\n",
    "        ])\n",
    "\n",
    "        dataset = Dataset()\n",
    "        trainSet, valSet = dataset.dataset()\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(f\"{model_save_path}/best_VGG19_tainable.keras\",\n",
    "                                        monitor='val_loss',\n",
    "                                        save_best_only=True,\n",
    "                                        mode='min',\n",
    "                                        verbose=1)\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        trained_model = model.fit(trainSet,\n",
    "                          validation_data=valSet,\n",
    "                          epochs=60,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          verbose=1,\n",
    "                          callbacks=[checkpoint_cb])\n",
    "\n",
    "        print(\"Training complete VGG19.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DS1PVFKQCvcX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742047863393,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class ResNet50:\n",
    "    def __init__(self, base_model):\n",
    "        self.base_model = base_model\n",
    "        self.base_model.trainable = True\n",
    "\n",
    "    def build_model(self):\n",
    "        prep = Preprocessing()\n",
    "        resize_and_rescale, data_augmentation = prep.preprocess()\n",
    "\n",
    "        model = Sequential([\n",
    "            layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            resize_and_rescale,\n",
    "            data_augmentation,\n",
    "            self.base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "            layers.Dropout(0.4),\n",
    "            layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(8, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        data = Dataset()\n",
    "        trainSet, valSet = data.dataset()\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(f\"{model_save_path}/best_ResNet50.keras\",\n",
    "                                        monitor='val_loss',\n",
    "                                        save_best_only=True,\n",
    "                                        mode='min',\n",
    "                                        verbose=1)\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        trained_model = model.fit(trainSet,\n",
    "                          validation_data=valSet,\n",
    "                          epochs=60,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          verbose=1,\n",
    "                          callbacks=[checkpoint_cb])\n",
    "\n",
    "        print(\"Training complete ResNet50.\")\n",
    "\n",
    "        return trained_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2moS9xzuDFTd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742047863505,
     "user_tz": -330,
     "elapsed": 111,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class Efficientnetb0:\n",
    "    def __init__(self, base_model):\n",
    "        self.base_model = base_model\n",
    "        self.base_model.trainable = True\n",
    "\n",
    "    def build_model(self, IMG_SIZE=224):\n",
    "        prep = Preprocessing()\n",
    "        resize_and_rescale, data_augmentation = prep.preprocess(IMG_SIZE= 224)\n",
    "\n",
    "        model = Sequential([\n",
    "            layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            resize_and_rescale,\n",
    "            data_augmentation,\n",
    "            self.base_model,\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1024, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(8, activation='softmax')  # 8 classes for classification\n",
    "        ])\n",
    "\n",
    "        dataset = Dataset()\n",
    "        trainSet, valSet = dataset.dataset()\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(f\"{model_save_path}/best_EfficientNet.keras\",\n",
    "                                        monitor='val_loss',\n",
    "                                        save_best_only=True,\n",
    "                                        mode='min',\n",
    "                                        verbose=1)\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        trained_model = model.fit(trainSet,\n",
    "                          validation_data=valSet,\n",
    "                          epochs=EPOCH,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          verbose=1,\n",
    "                          callbacks=[checkpoint_cb])\n",
    "\n",
    "        print(\"Training complete EfficientNet.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MfDE9ZyGvbpj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742054250465,
     "user_tz": -330,
     "elapsed": 5,
     "user": {
      "displayName": "Rounak_Test Mazumder",
      "userId": "16226630339958639180"
     }
    }
   },
   "source": [
    "class Model_Builder:\n",
    "    def __init__(self):\n",
    "        self.base_models = {\n",
    "            \"vgg16\": keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            \"vgg19\": keras.applications.VGG19(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            \"resnet50\": keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "            \"efficient0\": keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        }\n",
    "\n",
    "    def different_models(self):\n",
    "        custom_vgg16 = VGG16Model(self.base_models[\"vgg16\"])\n",
    "        model_vgg16 = custom_vgg16.build_model(IMG_SIZE)\n",
    "        custom_vgg19 = VGG19Model(self.base_models[\"vgg19\"])\n",
    "        model_vgg19 = custom_vgg19.build_model(IMG_SIZE)\n",
    "        custom_resnet50 = ResNet50(self.base_models[\"resnet50\"])\n",
    "        model_resnet50 = custom_resnet50.build_model()\n",
    "        custom_efficientnetb0 = Efficientnetb0(self.base_models[\"efficient0\"])\n",
    "        model_efficientnetb0 = custom_efficientnetb0.build_model(IMG_SIZE)\n",
    "        return model_vgg19, model_vgg16, model_resnet50, model_efficientnetb0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41bxYTS01SUT",
    "outputId": "38db8c9d-61c9-494b-9573-b148fa625aa9"
   },
   "source": [
    "model_builder = Model_Builder()\n",
    "models = model_builder.different_models()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
